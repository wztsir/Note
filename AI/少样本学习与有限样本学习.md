# 少样本学习与有限样本学习

其中不可靠的经验风险最小化是FSL的核心问题。基于采用先验知识来处理核心问题的方式，将不同的FSL方法分为三个方面：1）数据使用先验知识来增强监督经验，2）模型通过先验知识来约束假设空间，3）算法使用先验知识来改变假设空间搜索最佳假设的参数。在这种统一的分类法下，本文对不同类别的利弊进行了详尽的讨论。

## 先验概率

P(y|x) = ( P(y) * P(x|y) ) / P(x)

p(y)即先验概率，有时候有人为确定不够准确，或者统计得出

## 定义

现实的数据获取难度高，

1. 像人一样学习（可以根据几张人脸照片，查找对应的人）
2. 减少数据收集和计算开支
3. 有限样本下的学习

在机器学习中，训练单位是样本数据，通过数据来对模型进行优化；数据可以分为训练集、测试集和验证集。

在元学习中，训练单位是任务，一般有两个任务分别是训练任务（Train Tasks），和测试任务（Test Task）。

[与机器学习的对比](https://blog.csdn.net/weixin_44579633/article/details/124540237?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166601317016800184133313%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=166601317016800184133313&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~times_rank-1-124540237-null-null.142^v58^js_top,201^v3^control_1&utm_term=%E5%85%83%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187)

[元学习术语定义](https://blog.csdn.net/weixin_44422920/article/details/124229002?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166601317016800184133313%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=166601317016800184133313&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~times_rank-3-124229002-null-null.142^v58^js_top,201^v3^control_1&utm_term=%E5%85%83%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187)

## 分类

分别对数据集，模型和算法进行分类，可以得到下面的分类结果：

**迁移学习**:在迁移学习中，我们关注两个学习任务——源任务和目标任务。

**多任务学习和联合学习**:在多任务学习中，有K个> 1个学习任务，生成一个可以复用的机器学习模型

**元学习**:可以访问许多任务的数据，但对训练机器学习模型不感兴趣，元学习将生成一个过程，能够通过使用来自其他类似分类任务池的数据，为任何新的分类任务优化分类器。

the goal of meta-learning is to optimize hyperparameters with the goal of identifying a training algorithm that may perform well on new tasks.

## 元学习算法



###  (i) metric-based methods

基于度量的方法假设给定环境中的训练和测试任务共享一个公共的特征表示映射

这可以用来衡量数据点之间的相似性。

基于多个任务数据的相似性度量元学习可以用于实现非参数预测模型，而不需要对新任务进行训练。

现代基于度量的元学习方法包括匹配网络[3]、原型网络[4]和关系网络[5]。

该方法与高斯过程等模型中经常使用的经验贝叶斯方法一致，但需要注意的是，这里的数据来自不同的任务。





基于模型的方法优化一个超模型，该超模型直接将训练集从任务映射到模型。这种映射可以使用循环神经网络、卷积神经网络或超网络来实现。

![image-20221018172624689](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20221018172624689.png)

MatchingNet：Support set经过特征提取后，在embedding空间中利用Cosine来度量，通过对测试样本进行计算匹配程度来实现分类；

ProtoNet：利用聚类思想，将Support set投影到一个度量空间，在欧式距离度量的基础上获取向量均值，对测试样本计算到每个原型的距离，实现分类；

RelationNet：关系网络提出的relation module结构替换了MatchingNet和ProtoNet中的Cosine和欧式距离度量，使其成为一种学习的[非线性分类器](https://www.zhihu.com/search?q=非线性分类器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"165082133"})用于判断关系，实现分类。







###  (ii) model-based methods

作为基于模型的元学习的一个例子，通过元学习的上下文适应(CAVIA)算法。与基于优化的方案不同，该模型在所有任务中共享，而不是根据每个任务的训练数据进行调整。因此，模型参数向量可以被认为是跨任务共享的超参数9。适应于每个任务的是作为附加输入向量的上下文参数

2.6. 基于模型的元学习35模型如图2.5所示。这种选择的基本原理是向量φ可以嵌入关于任务的信息，这些信息可以控制模型的输出。我们将训练损失定义为Lptr (9， φ)

###  (iii) optimization-based methods

元学习背后的工作假设是，在观察一个新任务的训练数据集(通常是小的)之前，一个人可以从相关任务中访问一个更大的样本数据集。这就是所谓的元训练数据集。

元学习包括两个不同的阶段:

元训练:给定元训练数据集，优化一组超参数;

元测试:在元学习阶段完成后，显示目标任务(称为元测试任务)的数据，并使用元训练的超参数对模型参数进行优化。





特殊的 modular meta-learning 模块化元学习	





## MAML

[元学习算法](https://blog.csdn.net/qq_40913465/article/details/112608242?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166600911216782248580978%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166600911216782248580978&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-112608242-null-null.142^v58^js_top,201^v3^control_1&utm_term=%E5%85%83%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4187)

有一个图像数据集叫Omniglot：[https://github.com/brendenlake/omniglot](https://link.zhihu.com/?target=https%3A//github.com/brendenlake/omniglot)。Omniglot包含1623个不同的火星文字符，每个字符包含20个手写的case。这个任务是判断每个手写的case属于哪一个火星文字符。

![maml算法](D:\Note\AI\maml算法.jpg)





### IMAML

为了是防止模型梯度消失，加入正则项，罚

### Sharp-MAML



### FO-MAML



### ES-MAML



## Reptile

![reptile2](D:\Note\AI\reptile2.jpg)



训练过程：

<img src="D:\Note\AI\reptile.png" alt="reptile" style="zoom:50%;" />



## Modular Meta-Learning

模块化的元学习到目前为止所描述的方法都是以参数化为目标的。相比之下，模块化元学习的目标是快速组合泛化。模块化元学习不是通过超参数在任务之间传递知识，而是通过优化一组可重用的神经网络模块来推广新任务，这些模块可以以不同的方式组合起来解决新任务。通过跨任务重用模块，模块化元学习在某种意义上实现了“有限手段的无限使用”，并代表了一种可扩展的泛化方法，特别是在数据严重受限的情况下。。更正式地说，模块化元学习假设一个共享模块集M= [0(1)，， 0(M)]，大小为M，在元训练中进行优化。在测试期间，模块集是固定的，并选择模块的子集，组合并应用到新任务。通过从集合M中选择模块，这使得基于有限数据的有效适应成为可能。



设Sk(M)表示集合M中模块子集对特定任务k的分配。设(Sk(M))表示组合所选模块Sk(M)得到的模型。

元训练的损失

## 元学习的两层优化





## 元学习的统计学习理论



## 应用

### 1. 在迁移学习场景中的应用 

在迁移学习中，Pretrain-Finetune是一种常用的方式。这种方式的问题在于，经常需要尝试不同的迁移策略来达到最优效果。例如，某一层的参数是迁移还是[随机初始化](https://www.zhihu.com/search?q=随机初始化&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"471035337"})；当pretrain阶段模型和finetune阶段模型模型结构不一致时，[pretrain模型](https://www.zhihu.com/search?q=pretrain模型&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"471035337"})某一层的参数应该迁移到[finetune模型](https://www.zhihu.com/search?q=finetune模型&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"471035337"})的哪一层；每层迁移的强度多大等。对这些策略的尝试，会耗费大量时间。

***Learning What and Where to Transfer（ICML 2019）***中提出基于meta-learning的迁移学习方法，利用meta-learning学习什么样的迁移策略能够达到最优效果。



### 2.Domain Adaptation场景的应用



### 3.在图学习场景的应用

### 4. 在样本权重生成场景的应用









